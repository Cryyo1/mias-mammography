{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eric\\Anaconda2\\envs\\exts-aml2\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import preprocessing\n",
    "from mammo_utils import random_flip_image\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset 6, which included a lot of data augmentation to increase the size of the training set, possibly included too much data augmentation, because the results were terrible. I specifically think that it is possible that the tiling of ROIs created many images which did not contain any distinguishable features.\n",
    "\n",
    "I recreated the dataset, this time including the random cropping, flipping and rotation, but left out the tiling and tried to have each image include a full ROI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIAS Images (2465, 299, 299, 1)\n",
      "CBIS Train Images: (6760, 299, 299, 1)\n",
      "CBIS Test Images: (1879, 299, 299, 1)\n",
      "Normal Images: (65827, 299, 299, 1)\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "train_cbis_slices = np.load(os.path.join(\"data\", \"cbis_train_slices8.npy\"))\n",
    "train_cbis_labels = np.load(os.path.join(\"data\", \"cbis_train_labels8.npy\"))\n",
    "train_cbis_filenames = np.load(os.path.join(\"data\", \"cbis_train_names8.npy\"))\n",
    "\n",
    "test_cbis_slices = np.load(os.path.join(\"data\", \"cbis_test_slices8.npy\"))\n",
    "test_cbis_labels = np.load(os.path.join(\"data\", \"cbis_test_labels8.npy\"))\n",
    "test_cbis_filenames = np.load(os.path.join(\"data\", \"cbis_test_names8.npy\"))\n",
    "\n",
    "normal_slices_0 = np.load(os.path.join(\"data\", \"lumisys_slices.npy\"))\n",
    "normal_labels_0 = np.load(os.path.join(\"data\", \"lumisys_labels.npy\"))\n",
    "\n",
    "normal_slices_1 = np.load(os.path.join(\"data\", \"howtek_slices.npy\"))\n",
    "normal_labels_1 = np.load(os.path.join(\"data\", \"howtek_labels.npy\"))\n",
    "\n",
    "normal_slices_2 = np.load(os.path.join(\"data\", \"dba_slices.npy\"))\n",
    "normal_labels_2 = np.load(os.path.join(\"data\", \"dba_labels.npy\"))\n",
    "\n",
    "num_normal_images = len(normal_slices_0) + len(normal_slices_1) + len(normal_slices_2) #+ len(normal_slices_3) + len(normal_slices_4)\n",
    "normal_filenames = np.repeat(\"NORMAL\", num_normal_images)\n",
    "\n",
    "# concatenate the data\n",
    "all_normal_images = np.concatenate([normal_slices_0, normal_slices_1, normal_slices_2], axis=0)\n",
    "all_normal_labels = np.concatenate([normal_labels_0, normal_labels_1, normal_labels_2], axis=0)\n",
    "\n",
    "# import the mias data\n",
    "mias_images = np.load(os.path.join(\"data\", \"all_mias_slices.npy\"))\n",
    "mias_labels = np.load(os.path.join(\"data\", \"all_mias_labels.npy\"))\n",
    "mias_filenames = np.load(os.path.join(\"data\", \"all_mias_filenames.npy\"))\n",
    "\n",
    "print(\"MIAS Images\", mias_images.shape)\n",
    "print(\"CBIS Train Images:\", train_cbis_slices.shape)\n",
    "print(\"CBIS Test Images:\", test_cbis_slices.shape)\n",
    "print(\"Normal Images:\", all_normal_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# delete some variables to save memory\n",
    "del(normal_slices_0, normal_slices_1, normal_slices_2)\n",
    "del(normal_labels_0, normal_labels_1, normal_labels_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Train Normal Images: 33799\n",
      "Target Test Normal Images: 9394\n",
      "Target Total Normal Size: 43193\n",
      "Train Distribution: 0.16667077590670382\n",
      "Test Distribution: 0.16668145125521155\n"
     ]
    }
   ],
   "source": [
    "# in reality about 10% of mammograms are abnormal. Since I want to maximize recall I want my dataset to be skewed towards\n",
    "# having slightly more abnormal images. I need to divide the normal images up between the training and testing datasets\n",
    "# trying to keep the distribution within a certain range.\n",
    "total_cbis_images = train_cbis_slices.shape[0] + test_cbis_slices.shape[0]\n",
    "cbis_percent_train = train_cbis_slices.shape[0] / total_cbis_images\n",
    "total_normal_images = all_normal_images.shape[0]\n",
    "\n",
    "# our minimum percentage of normal images is 20%\n",
    "min_normal_data_size = total_cbis_images // 0.20\n",
    "min_normal_train_images = min_normal_data_size * cbis_percent_train\n",
    "min_normal_test_images = min_normal_data_size * (1 - cbis_percent_train)\n",
    "\n",
    "# our maximum number of normal images\n",
    "max_number_train_normal_images = total_normal_images * cbis_percent_train\n",
    "max_number_test_normal_images = total_normal_images - max_number_train_normal_images\n",
    "\n",
    "# the min of these two sets will be the actual number of normal images we use for each dataset\n",
    "target_number_train_normal_images = int(np.min([max_number_train_normal_images, min_normal_train_images]))\n",
    "target_number_test_normal_images = int(np.min([max_number_test_normal_images, min_normal_test_images]))\n",
    "\n",
    "print(\"Target Train Normal Images:\", target_number_train_normal_images)\n",
    "print(\"Target Test Normal Images:\", target_number_test_normal_images)\n",
    "print(\"Target Total Normal Size:\", target_number_train_normal_images + target_number_test_normal_images)\n",
    "\n",
    "print(\"Train Distribution:\", train_cbis_slices.shape[0] / (target_number_train_normal_images + train_cbis_slices.shape[0]))\n",
    "print(\"Test Distribution:\", test_cbis_slices.shape[0] / (target_number_test_normal_images + test_cbis_slices.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Normal Images: (33799, 299, 299, 1)\n",
      "Train Normal Labels: (33799,)\n",
      "Test Normal Images: (9394, 299, 299, 1)\n",
      "Test Normal Labels: (9394,)\n"
     ]
    }
   ],
   "source": [
    "# shuffle the data\n",
    "all_normal_images, all_normal_labels, normal_filenames = shuffle(all_normal_images, all_normal_labels, normal_filenames, random_state=101)\n",
    "\n",
    "# then take the appropriate number of rows\n",
    "train_normal_images = all_normal_images[:target_number_train_normal_images,:,:,:]\n",
    "train_normal_labels = all_normal_labels[:target_number_train_normal_images]\n",
    "train_normal_filenames = normal_filenames[:target_number_train_normal_images]\n",
    "\n",
    "test_normal_images = all_normal_images[target_number_train_normal_images:target_number_train_normal_images+target_number_test_normal_images,:,:,:]\n",
    "test_normal_labels = all_normal_labels[target_number_train_normal_images:target_number_train_normal_images+target_number_test_normal_images]\n",
    "test_normal_filenames = normal_filenames[target_number_train_normal_images:target_number_train_normal_images+target_number_test_normal_images]\n",
    "\n",
    "print(\"Train Normal Images:\", train_normal_images.shape)\n",
    "print(\"Train Normal Labels:\", train_normal_labels.shape)\n",
    "\n",
    "print(\"Test Normal Images:\", test_normal_images.shape)\n",
    "print(\"Test Normal Labels:\", test_normal_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images: (40559, 299, 299, 1)\n",
      "Train labels: (40559,)\n",
      "Train filenames: (40559,)\n"
     ]
    }
   ],
   "source": [
    "# concatenate the ddsm and cbis data\n",
    "train_images = np.concatenate([train_cbis_slices, train_normal_images], axis=0) # , mias_images\n",
    "train_labels = np.concatenate([train_cbis_labels, train_normal_labels], axis=0) # , mias_labels\n",
    "train_filenames = np.concatenate([train_cbis_filenames, train_normal_filenames]) # , mias_filenames\n",
    "\n",
    "print(\"Train images:\", train_images.shape)\n",
    "print(\"Train labels:\", train_labels.shape)\n",
    "print(\"Train filenames:\", train_filenames.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# delete old variables\n",
    "del(train_cbis_slices, train_normal_images, mias_images)\n",
    "del(train_cbis_labels, train_normal_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Images: (939, 299, 299, 1)\n",
      "CV Images: (940, 299, 299, 1)\n",
      "Test Labels: (939,)\n",
      "CV Labels: (940,)\n"
     ]
    }
   ],
   "source": [
    "# create the test data - in order to make sure the data sets don't overlap we will splt the cbis images evenly into test\n",
    "# and validation now. In order to try to segregate images by patient we will just split the data down the middle. \n",
    "# Since each mask can have at most 4 images this should keep overlap to a minimum\n",
    "test_size = test_cbis_slices.shape[0] // 2\n",
    "\n",
    "split_test_cbis_slices = test_cbis_slices[:test_size,:,:,:]\n",
    "split_cv_cbis_slices = test_cbis_slices[test_size:,:,:,:]\n",
    "\n",
    "split_test_cbis_labels = test_cbis_labels[:test_size]\n",
    "split_cv_cbis_labels = test_cbis_labels[test_size:]\n",
    "\n",
    "split_test_cbis_filenames = test_cbis_filenames[:test_size]\n",
    "split_cv_cbis_filenames = test_cbis_filenames[test_size:]\n",
    "\n",
    "print(\"Test Images:\", split_test_cbis_slices.shape)\n",
    "print(\"CV Images:\", split_cv_cbis_slices.shape)\n",
    "\n",
    "print(\"Test Labels:\", split_test_cbis_labels.shape)\n",
    "print(\"CV Labels:\", split_cv_cbis_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test images: (5636, 299, 299, 1)\n",
      "Test labels: (5636,)\n",
      "Test filenames: (5636,)\n",
      "CV images: (5637, 299, 299, 1)\n",
      "CV labels: (5637,)\n",
      "CV filenames: (5637,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# now shuffle and split the normal images \n",
    "split_test_normal_images, split_cv_normal_images, split_test_normal_labels, split_cv_normal_labels, split_test_normal_filenames, split_cv_normal_filenames  = train_test_split(test_normal_images, test_normal_labels, test_normal_filenames, test_size=0.5)\n",
    "\n",
    "# concatentate the data\n",
    "test_images = np.concatenate([split_test_cbis_slices, split_test_normal_images], axis=0)\n",
    "test_labels = np.concatenate([split_test_cbis_labels, split_test_normal_labels], axis=0)\n",
    "test_filenames = np.concatenate([split_test_cbis_filenames, split_test_normal_filenames])\n",
    "\n",
    "print(\"Test images:\", test_images.shape)\n",
    "print(\"Test labels:\", test_labels.shape)\n",
    "print(\"Test filenames:\", test_filenames.shape)\n",
    "\n",
    "# concatentate the data\n",
    "cv_images = np.concatenate([split_cv_cbis_slices, split_cv_normal_images], axis=0)\n",
    "cv_labels = np.concatenate([split_cv_cbis_labels, split_cv_normal_labels], axis=0)\n",
    "cv_filenames = np.concatenate([split_cv_cbis_filenames, split_cv_normal_filenames])\n",
    "\n",
    "print(\"CV images:\", cv_images.shape)\n",
    "print(\"CV labels:\", cv_labels.shape)\n",
    "print(\"CV filenames:\", cv_filenames.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# delete old vars\n",
    "del(test_cbis_slices, test_normal_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encode the labels\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(train_labels)\n",
    "# we want normal to be 0, so we'll do some transformations here\n",
    "train_labels_enc = le.transform(train_labels) + 1\n",
    "train_labels_enc[train_labels_enc == 5] = 0\n",
    "\n",
    "# encode the test labels\n",
    "test_labels_enc = le.transform(test_labels) + 1\n",
    "test_labels_enc[test_labels_enc == 5] = 0\n",
    "\n",
    "# encode the cv labels\n",
    "cv_labels_enc = le.transform(cv_labels) + 1\n",
    "cv_labels_enc[cv_labels_enc == 5] = 0\n",
    "\n",
    "# make the classes be in the same order as the labels\n",
    "classes = le.classes_\n",
    "classes = np.insert(classes, 0, 'NORMAL', axis=0)\n",
    "classes = classes[0:5]\n",
    "\n",
    "# make some other labels\n",
    "labels_normal = np.zeros(len(train_labels_enc)).astype(np.int32)\n",
    "labels_normal[train_labels_enc != 0] = 1\n",
    "\n",
    "np.save(os.path.join(\"data\", \"all_classes.npy\"), classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the distribution of the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.833329\n",
       "1    0.048201\n",
       "2    0.046056\n",
       "4    0.042506\n",
       "3    0.029907\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(train_labels_enc, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.833329\n",
       "1    0.166671\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(labels_normal, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffle the data and split it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_tr (40559, 299, 299, 1)\n",
      "X_te (5636, 299, 299, 1)\n",
      "X_cv (5637, 299, 299, 1)\n"
     ]
    }
   ],
   "source": [
    "# shuffle the training data\n",
    "X_tr, y_tr, train_filenames, labels_normal = shuffle(train_images, train_labels_enc, train_filenames, labels_normal, random_state=7241972)\n",
    "\n",
    "# shuffle the test data\n",
    "X_te, y_te, test_filenames = shuffle(test_images, test_labels_enc, test_filenames, random_state=228859)\n",
    "\n",
    "# shuffle the cv data\n",
    "X_cv, y_cv, cv_filenames = shuffle(cv_images, cv_labels_enc, cv_filenames, random_state=21777)\n",
    "\n",
    "\n",
    "print(\"X_tr\", X_tr.shape)\n",
    "print(\"X_te\", X_te.shape)\n",
    "print(\"X_cv\", X_cv.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the distribution of the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.833392\n",
       "2    0.101136\n",
       "4    0.065472\n",
       "dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(y_te, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.833245\n",
       "1    0.092780\n",
       "3    0.055526\n",
       "2    0.009757\n",
       "4    0.008693\n",
       "dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(y_cv, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write train data to tfrecords in 5 batches\n",
    "import math\n",
    "num_batches = 5\n",
    "batch_size = math.ceil(X_tr.shape[0] / num_batches)\n",
    "\n",
    "for i in range(num_batches):\n",
    "    train_path = os.path.join(\"data\",\"training8_\" + str(i) + '.tfrecords')\n",
    "    writer = tf.python_io.TFRecordWriter(train_path)\n",
    "    start_row = i * batch_size\n",
    "    end_row = start_row + batch_size - 1\n",
    "                              \n",
    "    for idx in range(start_row, end_row):\n",
    "        # try to get the data, if there is an error skip this index\n",
    "        try:\n",
    "            label = y_tr[idx]\n",
    "            label_normal = labels_normal[idx]\n",
    "            filename = train_filenames[idx].tostring()\n",
    "            image = X_tr[idx]\n",
    "            image_raw = image.tostring()\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "        example = tf.train.Example(\n",
    "            features=tf.train.Features(\n",
    "              feature={\n",
    "                # A Feature contains one of either a int64_list,\n",
    "                # float_list, or bytes_list\n",
    "                'label': _int64_feature(label),\n",
    "                'label_normal': _int64_feature(label_normal),\n",
    "                'filename': _bytes_feature(filename),\n",
    "                'image': _bytes_feature(image_raw),\n",
    "              }))\n",
    "\n",
    "        # use the proto object to serialize the example to a string\n",
    "        serialized = example.SerializeToString()\n",
    "        # write the serialized object to disk\n",
    "        writer.write(serialized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## save the test data\n",
    "np.save(os.path.join(\"data\", \"test8_data.npy\"), X_te)\n",
    "np.save(os.path.join(\"data\", \"test8_labels.npy\"), y_te)\n",
    "np.save(os.path.join(\"data\", \"test8_filenames.npy\"), test_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the validation data\n",
    "np.save(os.path.join(\"data\", \"cv8_data.npy\"), X_cv)\n",
    "np.save(os.path.join(\"data\", \"cv8_labels.npy\"), y_cv)\n",
    "np.save(os.path.join(\"data\", \"cv8_filenames.npy\"), cv_filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify that the data was written correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make sure everything was written properly by reading it back out\n",
    "def read_and_decode_single_example(filenames):\n",
    "    filename_queue = tf.train.string_input_producer(filenames, num_epochs=1)\n",
    "    \n",
    "    reader = tf.TFRecordReader()\n",
    "    \n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    # The serialized example is converted back to actual values.\n",
    "    # One needs to describe the format of the objects to be returned\n",
    "    features = tf.parse_single_example(\n",
    "        serialized_example,\n",
    "        features={\n",
    "            # We know the length of both fields. If not the\n",
    "            # tf.VarLenFeature could be used\n",
    "            'label': tf.FixedLenFeature([], tf.int64),\n",
    "            'image': tf.FixedLenFeature([], tf.string)\n",
    "        })\n",
    "    \n",
    "    # now return the converted data\n",
    "    label = features['label']\n",
    "    image = tf.decode_raw(features['image'], tf.uint8)\n",
    "    image = tf.reshape(image, [299, 299, 1])\n",
    "    \n",
    "    # scale the image\n",
    "    image = tf.image.per_image_standardization(image)\n",
    "    \n",
    "    # random flip image\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    \n",
    "    #image = tf.image.random_brightness(image, max_delta=10)\n",
    "    #image = tf.image.random_contrast(image, lower=0.2, upper=1.8)\n",
    "    \n",
    "    return label, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape must be rank 2 but is rank 1 for 'MatMul_10' (op: 'MatMul') with input shapes: [16,5], [5].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda2\\envs\\exts-aml2\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[1;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[0;32m    685\u001b[0m           \u001b[0mgraph_def_version\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_def_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m           input_tensors_as_shapes, status)\n\u001b[0m\u001b[0;32m    687\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\exts-aml2\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 473\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    474\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Shape must be rank 2 but is rank 1 for 'MatMul_10' (op: 'MatMul') with input shapes: [16,5], [5].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-29bad47ffed7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mclass_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mweight_per_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mglobal_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\exts-aml2\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[1;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[0;32m   2020\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2021\u001b[0m       return gen_math_ops._mat_mul(\n\u001b[1;32m-> 2022\u001b[1;33m           a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n\u001b[0m\u001b[0;32m   2023\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2024\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\exts-aml2\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36m_mat_mul\u001b[1;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[0;32m   2797\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m   2798\u001b[0m         \u001b[1;34m\"MatMul\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtranspose_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtranspose_b\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2799\u001b[1;33m         name=name)\n\u001b[0m\u001b[0;32m   2800\u001b[0m     \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2801\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\exts-aml2\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[0;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    788\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\exts-aml2\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[0;32m   3160\u001b[0m         op_def=op_def)\n\u001b[0;32m   3161\u001b[0m     self._create_op_helper(ret, compute_shapes=compute_shapes,\n\u001b[1;32m-> 3162\u001b[1;33m                            compute_device=compute_device)\n\u001b[0m\u001b[0;32m   3163\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\exts-aml2\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_op_helper\u001b[1;34m(self, op, compute_shapes, compute_device)\u001b[0m\n\u001b[0;32m   3206\u001b[0m     \u001b[1;31m# compute_shapes argument.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3207\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_c_op\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3208\u001b[1;33m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3209\u001b[0m     \u001b[1;31m# TODO(b/XXXX): move to Operation.__init__ once _USE_C_API flag is removed.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3210\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\exts-aml2\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m   2425\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_set_shapes_for_outputs_c_api\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2426\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2427\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_set_shapes_for_outputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2428\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2429\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\exts-aml2\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_set_shapes_for_outputs\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m   2398\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2399\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2400\u001b[1;33m   \u001b[0mshapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2401\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2402\u001b[0m     raise RuntimeError(\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\exts-aml2\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m   2328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2329\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2330\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2332\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\exts-aml2\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[1;34m(op, require_shape_fn)\u001b[0m\n\u001b[0;32m    625\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[0;32m    626\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 627\u001b[1;33m                                   require_shape_fn)\n\u001b[0m\u001b[0;32m    628\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m       \u001b[1;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\exts-aml2\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[1;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[0;32m    689\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 691\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    692\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    693\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Shape must be rank 2 but is rank 1 for 'MatMul_10' (op: 'MatMul') with input shapes: [16,5], [5]."
     ]
    }
   ],
   "source": [
    "label, image = read_and_decode_single_example([\"data/training8_0.tfrecords\", \"data/training8_1.tfrecords\"])\n",
    "\n",
    "#images_batch, labels_batch = tf.train.shuffle_batch([image, label], batch_size=16, capacity=2000, min_after_dequeue=1000)\n",
    "images_batch, labels_batch = tf.train.batch([image, label], batch_size=16, capacity=2000)\n",
    "\n",
    "# class_weight = tf.constant([4.0,1.0,1.0,1.0, 1.0])\n",
    "# weight_per_label = tf.transpose(tf.matmul(tf.cast(tf.one_hot(labels_batch, depth=5), tf.float32), tf.transpose(class_weight)))\n",
    "\n",
    "global_step = tf.Variable(0, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'weight_per_label' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-73aceaecc214>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mthreads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_queue_runners\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoord\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcoord\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mla_b\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mim_b\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfoo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabels_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimages_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_per_label\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Label:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mla_b\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'weight_per_label' is not defined"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.CancelledError'>, Run call was cancelled\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    \n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "    for j in range(3):\n",
    "        la_b, im_b = sess.run([labels_batch, images_batch])\n",
    "        \n",
    "        for i in range(6):\n",
    "            plt.imshow(im_b[i].reshape([299,299]))\n",
    "            plt.title(str(i) + \" - \" + str(la_b[i]))\n",
    "            plt.show()\n",
    "\n",
    "    coord.request_stop()\n",
    "    \n",
    "    # Wait for threads to stop\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
