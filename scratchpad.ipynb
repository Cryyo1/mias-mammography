{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eric\\Anaconda2\\envs\\exts-aml2\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from training_utils import download_file, get_batches, read_and_decode_single_example, load_validation_data, \\\n",
    "    download_data, evaluate_model, get_training_data, load_weights, flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model/model_s1.0.0.29l.8.2.ckpt\n",
      "Restoring model model_s1.0.0.29l.8.2\n",
      "Evaluating on test data\n",
      "Batch 1\n"
     ]
    }
   ],
   "source": [
    "config = tf.ConfigProto()\n",
    "how = \"normal\"\n",
    "which = 8\n",
    "batch_size = 32\n",
    "dataset = 8\n",
    "model_name = \"model_s1.0.0.29l.8.2\"\n",
    "## Evaluate on test data multi-class\n",
    "with tf.Session() as sess:\n",
    "    # restore the graph\n",
    "    saver = tf.train.import_meta_graph('./model/' + model_name + '.ckpt.meta', clear_devices=True)\n",
    "    \n",
    "    # restore the weights\n",
    "    saver.restore(sess, './model/' + model_name + '.ckpt')\n",
    "    \n",
    "    # get the graph\n",
    "    graph = tf.get_default_graph()\n",
    "    \n",
    "    # create the placeholders to feed\n",
    "    X = tf.placeholder(shape=[None, 299, 299, 1], dtype=tf.float32)\n",
    "    y = tf.placeholder(shape=[None], dtype=tf.int32)\n",
    "    training = graph.get_tensor_by_name(\"is_training_2:0\")\n",
    "    \n",
    "    # create the update ops\n",
    "    extra_update_ops = tf.get_collection('extra_update_ops')\n",
    "    probabilities = graph.get_tensor_by_name(\"probabilities:0\")\n",
    "    predictions = tf.argmax(probabilities, axis=1, output_type=tf.int64)\n",
    "    recall, rec_op = tf.metrics.recall(labels=y, predictions=predictions, updates_collections=tf.GraphKeys.UPDATE_OPS, name=\"recall\")\n",
    "    \n",
    "    # get the accuracy\n",
    "    accuracy, acc_op = tf.metrics.accuracy(\n",
    "        labels=y,\n",
    "        predictions=predictions,\n",
    "        updates_collections=tf.GraphKeys.UPDATE_OPS,\n",
    "        name=\"accuracy\",\n",
    "    )\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    \n",
    "    print(\"Restoring model\", model_name)\n",
    "    \n",
    "    # load the test data\n",
    "    X_te, y_te = load_validation_data(how=how, data=\"test\", which=dataset)\n",
    "    print(\"Evaluating on test data\")\n",
    "    \n",
    "    test_accuracy = []\n",
    "    test_recall = []\n",
    "    test_predictions = []\n",
    "    ground_truth = []\n",
    "    test_recall_value = 0\n",
    "    i = 1\n",
    "    for X_batch, y_batch in get_batches(X_te, y_te, batch_size, distort=False):\n",
    "        print(\"Batch\", i)\n",
    "        i += 1\n",
    "        _, yhat, test_acc_value = sess.run([extra_update_ops, predictions, accuracy], feed_dict=\n",
    "        {\n",
    "            X: X_batch,\n",
    "            y: y_batch,\n",
    "            training: False,\n",
    "        })\n",
    "\n",
    "        test_accuracy.append(test_acc_value)\n",
    "        test_recall.append(test_recall_value)\n",
    "        test_predictions.append(yhat)\n",
    "        ground_truth.append(y_batch)\n",
    "\n",
    "    # print the results\n",
    "    print()\n",
    "    print(\"Mean Test Accuracy:\", np.mean(test_accuracy))\n",
    "    print(\"Mean Test Recall:\", np.mean(test_recall))\n",
    "    \n",
    "    # unlist the predictions and truth\n",
    "    test_predictions = flatten(test_predictions)\n",
    "    ground_truth = flatten(ground_truth)\n",
    "    \n",
    "    # save the predictions and truth for review\n",
    "    np.save(os.path.join(\"data\", \"predictions_\" + model_name + \".npy\"), test_predictions)\n",
    "    np.save(os.path.join(\"data\", \"truth_\" + model_name + \".npy\"), ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
