{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image, ImageMath\n",
    "from scipy.misc import imresize\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import sys\n",
    "\n",
    "## import PGM files and return a numpy array\n",
    "def read_pgm(filename, byteorder='>'):\n",
    "    \"\"\"Return image data from a raw PGM file as numpy array.\n",
    "    Format specification: http://netpbm.sourceforge.net/doc/pgm.html\n",
    "    \"\"\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        buffer = f.read()\n",
    "    try:\n",
    "        header, width, height, maxval = re.search(\n",
    "            b\"(^P5\\s(?:\\s*#.*[\\r\\n])*\"\n",
    "            b\"(\\d+)\\s(?:\\s*#.*[\\r\\n])*\"\n",
    "            b\"(\\d+)\\s(?:\\s*#.*[\\r\\n])*\"\n",
    "            b\"(\\d+)\\s(?:\\s*#.*[\\r\\n]\\s)*)\", buffer).groups()\n",
    "    except AttributeError:\n",
    "        raise ValueError(\"Not a raw PGM file: '%s'\" % filename)\n",
    "        \n",
    "    image = np.frombuffer(buffer,\n",
    "                            dtype='u1' if int(maxval) < 256 else byteorder+'u2',\n",
    "                            count=int(width)*int(height),\n",
    "                            offset=len(header)\n",
    "                            ).reshape((int(height), int(width)))\n",
    "    \n",
    "    image_id = int(re.findall('([\\d]+)\\.', filename)[0])\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## flip every other image left to right so they are all oriented the same way\n",
    "def read_images(file):\n",
    "    # get the id of the images from the filename\n",
    "    image_id = int(re.findall('([\\d]+)\\.', file)[0])\n",
    "    print(image_id)\n",
    "    # read in the image\n",
    "    image = read_pgm(file)\n",
    "    \n",
    "    # if the ID is even flip the image\n",
    "    if image_id % 2 != 0:\n",
    "        image = np.fliplr(image)\n",
    "        #image = X_return[...,::-1,:]\n",
    "        \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Extract a tar.gz file\n",
    "def extract_tar(fname, dest=\"./data/pgms\"):\n",
    "    mode = \"r:gz\" if (fname.endswith(\"tar.gz\")) else \"r:\"\n",
    "    tar = tarfile.open(fname, mode)\n",
    "    tar.extractall(path=dest)\n",
    "    tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Download files from a URL to a file in the data directory\n",
    "def download_file(url, name):\n",
    "    # check that the data directory exists\n",
    "    try:\n",
    "        os.stat(\"data\")\n",
    "    except:\n",
    "        os.mkdir(\"data\")  \n",
    "    fname = wget.download(url, os.path.join('data',name)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## flatten a directory tree to a single directory\n",
    "def copy_subdirectories_to_directory(path, destination):\n",
    "    subdirectories = os.listdir(path)\n",
    "    for directory in subdirectories:\n",
    "        files = os.listdir(os.path.join(path, directory))\n",
    "        for file in files:\n",
    "            shutil.copy(os.path.join(path, directory, file), destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## given a path to a directory containing images, open all files in the directory, convert the images to\n",
    "## a numpy array, and return the array containing all the images, with the labels\n",
    "def convert_images_to_array(path, label_data=None):\n",
    "    data = []\n",
    "    labels = []\n",
    "    files = os.listdir(path)\n",
    "    for file in files:\n",
    "        img_data = Image.open(path + '/' + file)\n",
    "        arr = np.array(img_data)\n",
    "        \n",
    "        if label_data is not None:\n",
    "            # catch errors if there is no label for the image\n",
    "            try:\n",
    "                label = label_data.loc[file].CLASS\n",
    "                labels.append(label)\n",
    "                # if we have labels only add the image if there is a label\n",
    "                data.append(arr)\n",
    "            except:\n",
    "                print(\"Error with\", file)\n",
    "                continue\n",
    "        else:\n",
    "            data.append(arr)\n",
    "            \n",
    "    return np.array(data), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Open a png image, convert it to a JPG and save it\n",
    "def convert_png_to_jpg(path):\n",
    "    # open the image\n",
    "    im = Image.open(path)\n",
    "    im2 = ImageMath.eval('im/256', {'im':im}).convert('L')\n",
    "    \n",
    "    # create a new file name\n",
    "    path_array = path.split(\"\\\\\")\n",
    "    dir_path = \"\\\\\".join(path_array[:-1])\n",
    "    image_name = path_array[-1]\n",
    "    new_image_name = image_name.replace('.png','.jpg')\n",
    "    new_image_name\n",
    "    \n",
    "    \n",
    "    im2.convert('RGB').save(os.path.join(dir_path, new_image_name),\"JPEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## The scans from one particular scanner (DBA) have white sections cut out of them, possibly to hide personal information\n",
    "## this is only on the normal scans, so a convnet could use this information to identify the normal scans\n",
    "## to prevent this I will replace all white pixels with black, as there are no pure white pixels in a normal scan\n",
    "\n",
    "def remove_white_from_image(path, is_png=False):\n",
    "    # open the image\n",
    "    img = Image.open(path)\n",
    "    \n",
    "    if is_png:\n",
    "        # convert to rgb\n",
    "        img2 = ImageMath.eval('im/256', {'im':img}).convert('L')\n",
    "\n",
    "    # turn the image into an array\n",
    "    im_array = np.array(img2)\n",
    "    \n",
    "    # turn all white pixels to black\n",
    "    im_array[im_array == 255] = 0\n",
    "    \n",
    "    return im_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Takes in a PIL image, resizes it to new_size square and returns the new images\n",
    "def resize_image(img, new_size):\n",
    "    img2 = img.resize((new_size, new_size), PIL.Image.ANTIALIAS)\n",
    "    return img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## rename the files to include the patient id so we can match the image up with the labels\n",
    "## also copy the images to a single directory so we have them all in one place\n",
    "def rename_and_copy_files(path, sourcedir=\"JPEG512\", destdir=\"AllJPEGS512\"):\n",
    "    directories = os.listdir(path+sourcedir)\n",
    "    source_path = path + sourcedir + \"/\"\n",
    "    destination_path = path + destdir + \"/\"\n",
    "                    \n",
    "    # make sure the destination directory exists\n",
    "    try:\n",
    "        os.stat(destination_path)\n",
    "    except:\n",
    "        os.mkdir(destination_path)  \n",
    "    \n",
    "    # keep a counter so each file has a unique name\n",
    "    i = 1\n",
    "    \n",
    "    # loop through the directories\n",
    "    for directory in directories:\n",
    "        # get the patient number and image type from the directory name\n",
    "        patient_id = str(re.findall(\"_(P_[\\d]+)_\", directory))\n",
    "        if len(patient_id) > 0:\n",
    "            patient_id = patient_id[0]\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "        image_side = str(re.findall(\"_(LEFT|RIGHT)_\", directory))\n",
    "        \n",
    "        if len(image_side) > 0:\n",
    "            image_side = image_side[0]\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        image_type = str(re.findall(\"(CC|MLO)\", directory))\n",
    "        if len(image_type) > 0:\n",
    "            image_type = image_type[0]\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        if not patient_id:\n",
    "            continue\n",
    "            \n",
    "        # get the subdirectories\n",
    "        subdir = os.listdir(source_path+directory)\n",
    "\n",
    "        # get the next level of subdirectories\n",
    "        subsubdir = os.listdir(source_path+directory+'/'+subdir[0])\n",
    "\n",
    "        # get the files \n",
    "        files = os.listdir(source_path+directory+'/'+subdir[0]+'/'+subsubdir[0])\n",
    "        path = source_path+directory+'/'+subdir[0]+'/'+subsubdir[0]\n",
    "\n",
    "        for file in files:\n",
    "            # rename the file so we know where it came from\n",
    "            # some of the data is not properly labeled, if that is the case skip it since we won't be able to label it\n",
    "            try:\n",
    "                new_name = patient_id+'_'+image_side+'_'+image_type+'.jpg'\n",
    "                \n",
    "                # if the file already exists in the final destination, rename it\n",
    "                if os.path.exists(destination_path + new_name):\n",
    "                    new_name = patient_id+'_'+image_side+'_'+image_type+'_1.jpg'\n",
    "                \n",
    "                new_path = path + new_name\n",
    "                os.rename(path+'/'+file, new_path)\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "            ## copy the files so they are all in one directory\n",
    "            shutil.copy(new_path, destination_path)\n",
    "\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## function to trim pixels off all sides of an image, should help to remove white borders and such\n",
    "def remove_margins(image_arr, margin=20):\n",
    "    h, w = image_arr.shape\n",
    "    \n",
    "    new_image = image_arr[margin:h-margin,margin:w-margin]\n",
    "    \n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## input: path to mask image PNG\n",
    "## opens the mask, reduces its size by half, finds the borders of the mask and returns the center of the mass\n",
    "## if the mass is bigger than the slice it returns the upper left and lower right corners of the mask as tuples\n",
    "## which will be used to create multiple slices\n",
    "## returns: center_row - int with center row of mask, or tuple with edges of the mask if the mask is bigger than the slice\n",
    "##          center_col - idem\n",
    "##          too_big - boolean indicating if the mask is bigger than the slice\n",
    "def create_mask(mask_path, full_image_arr, slice_size=598, return_size=False, half=True, output=True):\n",
    "    # open the mask\n",
    "    mask = PIL.Image.open(mask_path)\n",
    "    \n",
    "    # cut the image in half\n",
    "    if half:\n",
    "        h, w = mask.size\n",
    "        new_size = ( h // 2, w // 2)\n",
    "        mask.thumbnail(new_size, PIL.Image.ANTIALIAS)\n",
    "\n",
    "    # turn it into an arry\n",
    "    mask_arr = np.array(mask)\n",
    "    \n",
    "    # get rid of the extras dimensions\n",
    "    mask_arr = mask_arr[:,:,0]\n",
    "    \n",
    "    # some images have white on the borders which may be something a convnet can use to predict. To prevent this,\n",
    "    # if the full image has more than 50,000 white pixels we will trim the edges by 20 pixels on either side\n",
    "    if np.sum(np.sum(full_image_arr >= 225)) > 20000:\n",
    "        full_image_arr = remove_margins(full_image_arr)\n",
    "        mask_arr = remove_margins(mask_arr)\n",
    "        if output:\n",
    "            print(\"Trimming borders\", mask_path)\n",
    "            \n",
    "    # make sure the mask is the same size as the full image, if not there is a problem, don't use this one\n",
    "    if mask_arr.shape != full_image_arr.shape:\n",
    "        # see if the ratios are the same\n",
    "        mask_ratio = mask_arr.shape[0] / mask_arr.shape[1]\n",
    "        image_ratio = full_image_arr.shape[0] / full_image_arr.shape[1]\n",
    "        \n",
    "        if abs(mask_ratio - image_ratio) <=  1e-03:\n",
    "            if output:\n",
    "                print(\"Mishaped mask, resizing mask\", mask_path)\n",
    "            \n",
    "            # reshape the mask to match the image\n",
    "            mask_arr = imresize(mask_arr, full_image_arr.shape)\n",
    "            \n",
    "        else:\n",
    "            if output:\n",
    "                print(\"Mask shape:\", mask_arr.shape)\n",
    "                print(\"Image shape:\", full_image_arr.shape)\n",
    "            print(\"Mask shape doesn't match image!\", mask_path)\n",
    "            return 0, 0, False, full_image_arr, 0\n",
    "    \n",
    "    # find the borders\n",
    "    mask_mask = mask_arr == 255\n",
    "\n",
    "    # does each row or column have a white pixel in it?\n",
    "    cols = np.sum(mask_mask, axis=0)\n",
    "    rows = np.sum(mask_mask, axis=1)\n",
    "\n",
    "    # figure out where the corners are\n",
    "    first_col = np.argmax(cols > 0)\n",
    "    last_col = mask_arr.shape[1] - np.argmax(np.flip(cols, axis=0) > 0)\n",
    "    center_col = int((first_col + last_col) / 2)\n",
    "\n",
    "    first_row = np.argmax(rows > 0)\n",
    "    last_row = mask_arr.shape[0] - np.argmax(np.flip(rows, axis=0) > 0)\n",
    "    center_row = int((first_row + last_row) / 2)\n",
    "    \n",
    "    col_size = last_col - first_col\n",
    "    row_size = last_row - first_row\n",
    "    \n",
    "    mask_size = [row_size, col_size]\n",
    "    \n",
    "    # signal if the mask is bigger than the slice\n",
    "    too_big = False\n",
    "    \n",
    "    if (last_col - first_col > slice_size + 30) or (last_row - first_row > slice_size + 30):\n",
    "        too_big = True\n",
    "    \n",
    "  \n",
    "    return center_row, center_col, too_big, full_image_arr, mask_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## takes a PIL image as input, scales the image to half size and returns it\n",
    "def half_image(image):\n",
    "    h,w = image.size\n",
    "    \n",
    "    new_size = ( h // 2, w // 2)\n",
    "    image.thumbnail(new_size, PIL.Image.ANTIALIAS)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## function to read images contained in a directory, create slices from them and return a numpy array of the slices\n",
    "## with labels. The threshholds are used to filter out images which are not usable or interesting. \n",
    "def create_slices(path, output=True, var_upper_threshhold=0, var_lower_threshhold=0, mean_threshold=0, stride=200):\n",
    "    files = os.listdir(path)\n",
    "    normal_slices = []\n",
    "    normal_labels = []\n",
    "    \n",
    "    i = 0\n",
    "    for file in files:\n",
    "        if output:\n",
    "            print(i, \"-\", file)\n",
    "        i += 1\n",
    "        tiles = slice_normal_image(os.path.join(path, file), var_upper_threshold=var_upper_threshhold, var_lower_threshold=var_lower_threshhold, mean_threshold=mean_threshold, stride=stride)\n",
    "        for tile in tiles:\n",
    "            normal_slices.append(tile)\n",
    "            normal_labels.append(\"NORMAL\")\n",
    "        \n",
    "        #if i > 400:\n",
    "        #    break\n",
    "            \n",
    "    assert(len(normal_slices) == len(normal_labels))\n",
    "    \n",
    "    return np.array(normal_slices), np.array(normal_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Loads a PNG image, converts it to an RGB numpy array, slices it into tiles and returns the tiles which contain usable images\n",
    "## Var and Mean thresholds can be used to only keep images with usable information in them.\n",
    "## Inputs: path - path to image\n",
    "##         var_threshold - only keep images with a variance BELOW this\n",
    "##         mean_threshold - only keep images with a mean ABOVE this\n",
    "def slice_normal_image(path, var_upper_threshold=0, var_lower_threshold=0, mean_threshold=0, stride=200):\n",
    "    # load the image\n",
    "    img = PIL.Image.open(path)\n",
    "    \n",
    "    # convert the image to RGB\n",
    "    img = PIL.ImageMath.eval('im/256', {'im':img}).convert('L')\n",
    "    \n",
    "    # size the image down by a random factor for variety and to try to match what we did to the cbis images\n",
    "    scale_by = np.random.uniform(low=1.8, high=3.2)\n",
    "    h, w = img.size\n",
    "    new_size = ( h // scale_by, w // scale_by)\n",
    "    img.thumbnail(new_size, PIL.Image.ANTIALIAS)\n",
    "    \n",
    "    # convert to an array\n",
    "    img = np.array(img)\n",
    "    \n",
    "    # remove white pixels\n",
    "    img[img == 255] = 0\n",
    "    \n",
    "    # remove 7% from each side of image to eliminate borders\n",
    "    h, w = img.shape\n",
    "    hmargin = int(h * 0.07)\n",
    "    wmargin = int(w * 0.07)\n",
    "    img = img[hmargin:h-hmargin, wmargin:w-wmargin]\n",
    "    \n",
    "    # slice the image into 299x299 tiles\n",
    "    size = 299\n",
    "    tiles = [img[x:x+size,y:y+size] for x in range(0,img.shape[0],stride) for y in range(0,img.shape[1],stride)]\n",
    "    usable_tiles = []\n",
    "    \n",
    "    # for each tile:\n",
    "    for i in range(len(tiles)):\n",
    "        # make sure tile has correct shape\n",
    "        if tiles[i].shape == (size,size):\n",
    "            # make sure the tile doesn't have too many white or black pixels, that indicates it is not useful\n",
    "            if (np.sum(np.sum(tiles[i] >= 225)) < 100) and (np.sum(np.sum(tiles[i] <= 20)) <= 50000):\n",
    "                # make sure tile has stuff in it\n",
    "                if np.mean(tiles[i]) >= mean_threshold:\n",
    "                    # make sure the tile contains image and not mostly empty space\n",
    "                    if np.var(tiles[i]) <= var_upper_threshold:\n",
    "                        if np.var(tiles[i]) >= var_lower_threshold:\n",
    "                            # reshape the tile so they will work with the convnet\n",
    "                            usable_tiles.append(random_flip_image(tiles[i].reshape(299,299,1)))\n",
    "\n",
    "    return usable_tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## create a random offset for slices to have some variety in the data\n",
    "def get_fuzzy_offset(roi_size, slice_size=299):\n",
    "    fuzz_factor = (slice_size - roi_size - 20) // 2\n",
    "    \n",
    "    if fuzz_factor <= 0:\n",
    "        fuzz_factor = 1\n",
    "    \n",
    "    fuzz_sign_h = np.random.binomial(1,0.5)\n",
    "    fuzz_sign_w = np.random.binomial(1,0.5)\n",
    "\n",
    "    fuzz_offset_w = np.random.randint(low=0, high=fuzz_factor)\n",
    "    if fuzz_sign_w == 0:\n",
    "        fuzz_offset_w = 0 - fuzz_offset_w\n",
    "\n",
    "    fuzz_offset_h = np.random.randint(low=0, high=fuzz_factor)\n",
    "    if fuzz_sign_h == 0:\n",
    "        fuzz_offset_h = 0 - fuzz_offset_h\n",
    "    \n",
    "    return fuzz_offset_h, fuzz_offset_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Progress bar taken from https://gist.github.com/vladignatyev/06860ec2040cb497f0f3\n",
    "def progress(count, total, status=''):\n",
    "    bar_len = 60\n",
    "    filled_len = int(round(bar_len * count / float(total)))\n",
    "\n",
    "    percents = round(100.0 * count / float(total), 1)\n",
    "    bar = '=' * filled_len + '-' * (bar_len - filled_len)\n",
    "\n",
    "    sys.stdout.write('[%s] %s%s ...%s\\r' % (bar, percents, '%', status))\n",
    "    sys.stdout.flush()  # As suggested by Rom Ruben (see: http://stackoverflow.com/questions/3173320/text-progress-bar-in-the-console/27871113#comment50529068_27871113)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_roi_edges(center_col, center_row, img_height, img_width, fuzz_offset_w=0, fuzz_offset_h=0, scale_factor=1, slice_size=299):\n",
    "    # slice margin\n",
    "    slice_margin = slice_size // 2\n",
    "    \n",
    "    # figure out the new center of the ROI\n",
    "    center_col_scaled = int(center_col * scale_factor)\n",
    "    center_row_scaled = int(center_row * scale_factor)\n",
    "    \n",
    "    start_col = int(center_col_scaled - slice_margin + fuzz_offset_h)\n",
    "    end_col = int(start_col + slice_size)\n",
    "    \n",
    "    if start_col < 0:\n",
    "        start_col = 0\n",
    "        end_col = slice_size\n",
    "    elif end_col > img_width:\n",
    "        end_col = img_width\n",
    "        start_col = int(img_width - slice_size)\n",
    "        \n",
    "    start_row = int(center_row_scaled - slice_margin + fuzz_offset_w)\n",
    "    end_row = int(start_row + slice_size)\n",
    "    \n",
    "    if start_row < 0:\n",
    "        start_row = 0\n",
    "        end_row = slice_size\n",
    "    elif end_row > img_height:\n",
    "        end_row = img_height\n",
    "        start_row = int(img_height - slice_size)\n",
    "     \n",
    "    return start_row, end_row, start_col, end_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## randomly rotate an image\n",
    "def random_rotate_image(img):\n",
    "    rotations = np.random.randint(low=-3, high=3)\n",
    "    return np.rot90(img, rotations)\n",
    "\n",
    "## randomly flip an image left-right, up-down or both and return it\n",
    "def random_flip_image(img):\n",
    "    fliplr = np.random.binomial(1,0.5)\n",
    "    flipud = np.random.binomial(1,0.5)\n",
    "    \n",
    "    if fliplr:\n",
    "        img = np.flip(img, 1)\n",
    "    if flipud:\n",
    "        img = np.flip(img, 0)\n",
    "        \n",
    "    return random_rotate_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## cut out tiles from images given the ROI center and size, with padding, random offset and random rotation\n",
    "def extract_slice(img, center_col, center_row, roi_size, padding=1.2, context_scale=2, return_slice_size=299, distort=True):\n",
    "    # figure out the size of the tile we will extract\n",
    "    tile_size = int(roi_size * context_scale)\n",
    "    \n",
    "    # if the tile is very small enlarge it so we don't zoom too much and distort the images\n",
    "    if tile_size < 300:\n",
    "        tile_size = 300\n",
    "    \n",
    "    # get random offset\n",
    "    fuzz_offset_h, fuzz_offset_w = get_fuzzy_offset(int(roi_size * padding), slice_size=tile_size)\n",
    "    \n",
    "    # define boundaries for the abnormality\n",
    "    image_h = img.shape[0]\n",
    "    image_w = img.shape[1]\n",
    "    start_row, end_row, start_col, end_col = get_roi_edges(center_col, center_row, image_h, image_w, fuzz_offset_w, fuzz_offset_h, 1, slice_size=tile_size)\n",
    "    \n",
    "    # slice the ROI out of the image\n",
    "    img_slice = img[start_row:end_row, start_col:end_col]\n",
    "\n",
    "    # cut the slice down to proper size\n",
    "    try:\n",
    "        img_slice = imresize(img_slice, (return_slice_size,return_slice_size))\n",
    "    except:\n",
    "        print(\"Error resizing tile\")\n",
    "        return np.array([1,1])\n",
    "    \n",
    "    # if everything is usable return it, otherwise return an unusable slice\n",
    "    if img_slice.shape == (return_slice_size,return_slice_size):\n",
    "        if distort:\n",
    "            return random_flip_image(img_slice.reshape(return_slice_size,return_slice_size,1))\n",
    "        else:\n",
    "            return img_slice.reshape(return_slice_size,return_slice_size,1)\n",
    "    else:\n",
    "        return np.array([1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## remove extraneous characters from end of file name and return it\n",
    "def clean_name(name):\n",
    "    patient_id = re.findall(\"(P_[\\d]+)_\", name)\n",
    "    if len(patient_id) > 0:\n",
    "        patient_id = patient_id[0]\n",
    "    else:\n",
    "        print(\"Name error\")\n",
    "        return name\n",
    "\n",
    "    image_side = re.findall(\"_(LEFT|RIGHT)_\", name)\n",
    "\n",
    "    if len(image_side) > 0:\n",
    "        image_side = image_side[0]\n",
    "    else:\n",
    "        print(\"Side error\")\n",
    "        return name\n",
    "\n",
    "    image_type = re.findall(\"(CC|MLO)\", name)\n",
    "    if len(image_type) > 0:\n",
    "        image_type = image_type[0]\n",
    "    else:\n",
    "        return name\n",
    "    \n",
    "    return patient_id + \"_\" + image_side + \"_\" + image_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_metrics(model_name, classification, dataset, model_dir=None, vline=None, vlabel=None):\n",
    "    if model_dir == None:\n",
    "        model_dir = model_name\n",
    "        \n",
    "    train_acc_values = np.load(os.path.join(\"data\", \"results\", model_dir, model_name + \"train_acc.npy\"))\n",
    "    valid_acc_values = np.load(os.path.join(\"data\", \"results\", model_dir, model_name + \"cv_acc.npy\"))\n",
    "\n",
    "    train_cost_values = np.load(os.path.join(\"data\", \"results\", model_dir, model_name + \"train_loss.npy\"))\n",
    "    valid_cost_values = np.load(os.path.join(\"data\", \"results\", model_dir, model_name + \"cv_loss.npy\"))\n",
    "\n",
    "    train_recall_values = np.load(os.path.join(\"data\", \"results\", model_dir, model_name + \"train_recall.npy\"))\n",
    "    valid_recall_values = np.load(os.path.join(\"data\", \"results\", model_dir, model_name + \"cv_recall.npy\"))\n",
    "\n",
    "    train_lr_values = np.load(os.path.join(\"data\", \"results\", model_dir, model_name + \"train_lr.npy\"))\n",
    "    \n",
    "    # initialize the plots\n",
    "    f, ax = plt.subplots(1, 4, figsize=(24, 5))\n",
    "\n",
    "    ax[0].plot(valid_acc_values, color=\"red\", label=\"Validation\")\n",
    "    ax[0].plot(train_acc_values, color=\"blue\", label=\"Training\")\n",
    "    ax[0].axhline(y=0.83, color=\"salmon\", label=\"Baseline Accuracy\")\n",
    "    ax[0].set_title('Validation accuracy: {:.4f} (mean last 4)'.format(np.mean(valid_acc_values[-4:])))\n",
    "    ax[0].set_xlabel('Epoch')\n",
    "    ax[0].set_ylabel('Accuracy')\n",
    "    ax[0].set_ylim([0.3,1.0])\n",
    "\n",
    "    # draw vertical line if one is passed in\n",
    "    if vline is not None:\n",
    "        ax[0].axvline(x=vline, color=\"black\", label=vlabel)\n",
    "        \n",
    "    ax[0].legend()\n",
    "    \n",
    "    ax[1].plot(valid_cost_values, color=\"red\", label=\"Validation\")\n",
    "    ax[1].plot(train_cost_values, color=\"blue\", label=\"Training\")\n",
    "    ax[1].set_title('Validation x-entropy: {:.3f} (mean last 4)'.format(np.mean(valid_cost_values[-4:])))\n",
    "    ax[1].set_xlabel('Epoch')\n",
    "    ax[1].set_ylabel('Cross Entropy')\n",
    "    ax[1].set_ylim([0,2.0])\n",
    "    ax[1].legend()\n",
    "\n",
    "    ax[2].plot(train_recall_values, color=\"red\", label=\"Validation\")\n",
    "    ax[2].plot(valid_recall_values, color=\"blue\", label=\"Training\")\n",
    "    ax[2].set_title('Validation Recall: {:.3f} (mean last 4)'.format(np.mean(valid_recall_values[-4:])))\n",
    "    ax[2].set_xlabel('Epoch')\n",
    "    ax[2].set_ylabel('Recall')\n",
    "    ax[2].legend()\n",
    "\n",
    "    ax[3].plot(train_lr_values)\n",
    "    ax[3].set_title(\"Learning rate: {:.6f}\".format(np.mean(train_lr_values[-1:])))\n",
    "    ax[3].set_xlabel(\"Epoch\")\n",
    "    ax[3].set_ylabel(\"Learning Rate\")\n",
    "\n",
    "    f.suptitle(\"Results for \" + model_name + \" \" + classification + \" (Dataset \" + str(dataset) + \")\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stats_on_images(array):\n",
    "    print(\"Var:\", np.var(array))\n",
    "    print(\"Max:\", np.max(array))\n",
    "    print(\"Min:\", np.min(array))\n",
    "    print(\"Mean:\", np.mean(array)) \n",
    "    \n",
    "def scale_data(input_data, new_min=0.0, new_max=255.0):\n",
    "    old_max = np.max(input_data)\n",
    "    old_min = np.min(input_data)\n",
    "    \n",
    "    adjustment_factor = (new_max - new_min) / (old_max - old_min)\n",
    "    scaled_data = adjustment_factor * (input_data - old_min) + new_min\n",
    "    \n",
    "    return scaled_data\n",
    "\n",
    "def per_image_summary(data):\n",
    "    maxes = []\n",
    "    mins = []\n",
    "    means = []\n",
    "    sigmas = []\n",
    "    \n",
    "    for item in data:\n",
    "        maxes.append(np.max(item))\n",
    "        mins.append(np.min(item))\n",
    "        means.append(np.mean(item))\n",
    "        sigmas.append(np.std(item))\n",
    "        \n",
    "    return maxes, mins, means, sigmas\n",
    "\n",
    "def plot_data_summaries(data):\n",
    "    maxes, mins, means, sigmas = per_image_summary(data)\n",
    "    \n",
    "    f, ax = plt.subplots(1, 4, figsize=(24, 5))\n",
    "    \n",
    "    ax[0].hist(maxes, bins=np.arange(0,250,25))\n",
    "    ax[0].set_title(\"Max\")\n",
    "    \n",
    "    ax[1].hist(mins, bins=np.arange(0,250,25))\n",
    "    ax[1].set_title(\"Min\")\n",
    "    \n",
    "    ax[2].hist(means, bins=np.arange(0,250,25))\n",
    "    ax[2].set_title(\"Mean\")\n",
    "    \n",
    "    ax[3].hist(sigmas, bins=np.arange(0,80,10))\n",
    "    ax[3].set_title(\"Std\")\n",
    "    \n",
    "def adjust_contrast(data, contrast):\n",
    "    mu = np.mean(data)\n",
    "    \n",
    "    data = (data - mu) * contrast + mu\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten(l):\n",
    "    out = []\n",
    "    for item in l:\n",
    "        if isinstance(item, (list, tuple)):\n",
    "            out.extend(flatten(item))\n",
    "        else:\n",
    "            out.append(item)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# determines if a 2d array has more than max_percentage of its values the same\n",
    "def array_repeats(data, max_percentage=0.4):\n",
    "    # count number of times each value appears in the array\n",
    "    counts = np.unique(data, return_counts=True)[1]\n",
    "    \n",
    "    # get the number of elements in the array\n",
    "    array_shape = data.shape[0] * data.shape[1]\n",
    "    \n",
    "    if np.max(counts) > array_shape * max_percentage:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trim_edges_from_image(image):\n",
    "    # trim from the left side\n",
    "    h = image.shape[0]\n",
    "    \n",
    "    # figure if a column contains almost all black pixels\n",
    "    black_cols = np.sum(image <= 9, axis=0) == h\n",
    "    \n",
    "    return image[:,~black_cols]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
